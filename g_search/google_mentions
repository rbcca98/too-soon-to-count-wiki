# -*- coding: utf-8 -*-
"""google_mentions

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hBApATVmykr58QDooTfAlt4VOvV51H2J
"""

from google.colab import drive
drive.mount('/content/drive')

import csv
import pandas as pd
names = []

with open('/content/drive/My Drive/Wiki/gsearchlinks.csv', newline='') as csvfile:
  spamreader = csv.reader(csvfile, delimiter=',')
  for row in spamreader:
    names.append(row[0])
print(names)

k=[]
for i in names:
  if 'wiki' in i:
    j=i.replace('/wiki/Wikipedia:Articles_for_deletion/','')
    k.append(j)
  else:
    k.append(i)
print(k)

new_names=[]
for m in k:
  if "(" in m:
    i=str(m)
    index = i.find("(")
    index= index-1
    new_name=i.replace(i[index:],"")
    #new_name=new_name.replace("['","")
    new_names.append(new_name)
    #print(new_name)
  else:
    new_names.append(m)
print(new_names)

kk=[]
for i in new_names:
  jj='"'+i+'"'
  kk.append(jj)
print(kk)

oo=[]
for ii in kk:
  mm=ii.replace('_','+')
  mm=mm+'+'
  oo.append(mm)
print(oo)

import csv
import pandas as pd
occ = []

with open('/content/drive/My Drive/Wiki/FINAL_all_wikidata.csv', newline='') as csvfile:
  spamreader = csv.reader(csvfile, delimiter=',')
  for row in spamreader:
    occ.append(row[7])
print(occ)

zz=[]
num=range(0,2320)
for ii in num:
  x=occ[ii]
  y=oo[ii]
  x=x.replace(' ','"+"')
  x=x.replace('-','"+"')
  x='"'+x+'"'
  z=y+x
  zz.append(z)
print(zz)

linx=[]
for z in zz:
  xx='https://www.google.com/search?q='+z
  if 'no"+"search"+"results' in xx:
    linx.append('N/A')
  elif 'occupation"+"unknown' in xx:
    linx.append('N/A')
  else:
    linx.append(xx)
print(linx)

import pandas as pd
df = pd.DataFrame(linx)
df.to_csv('/content/drive/My Drive/Wiki/gsearchlinks.csv', index=False, header=False)



!pip install selenium
!apt-get update # to update ubuntu to correctly run apt install
!apt install chromium-chromedriver
!cp /usr/lib/chromium-browser/chromedriver /usr/bin
import sys
sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')
from selenium import webdriver
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)
#wd.get("https://www.google.com")

occ=[]
import requests
from bs4 import BeautifulSoup
for i in names[458:2320]:
  if 'N/A' in i:
    occ.append('N/A')
    print('N/A')
  elif 'Google Search Link' in i:
    occ.append('Google Result Number')
    print('Google Result Number')
  else:
    #driver = webdriver.Chrome(executable_path='C:/path/to/chromedriver.exe')
    #wd = webdriver.Chrome('chromedriver',options=options)
    wd.get(i)
    #page = requests.get(i)
    soup = BeautifulSoup(wd.page_source, 'html.parser')
    results = soup.find(id='result-stats')
    #print(str(type(results)))
    if str(type((results)))=="<class 'NoneType'>":
      occ.append('error')
      print('error')
    else:
      #elems = results.find('div', class_='wikibase-snakview-value wikibase-snakview-variation-valuesnak')
      occ.append(results.text.strip())
      print(results.text.strip())

export PATH=$PATH:/path to geckodriver/
